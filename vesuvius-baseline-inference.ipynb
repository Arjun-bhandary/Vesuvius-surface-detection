{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5795f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T03:54:03.219509Z",
     "iopub.status.busy": "2025-12-11T03:54:03.219216Z",
     "iopub.status.idle": "2025-12-11T03:54:37.456492Z",
     "shell.execute_reply": "2025-12-11T03:54:37.455103Z",
     "shell.execute_reply.started": "2025-12-11T03:54:03.219480Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-12-11T04:21:28.519469",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --no-index --find-links=\"/kaggle/input/surface-package-scraper\" -q pytorch_lightning monai albumentations imagecodecs --no-deps # \"numpy==1.26.4\" \"scipy==1.15.3\"\n",
    "!pip uninstall -q -y tensorflow  # preventing AttributeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290cf009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T03:54:37.459483Z",
     "iopub.status.busy": "2025-12-11T03:54:37.459170Z",
     "iopub.status.idle": "2025-12-11T03:54:37.464464Z",
     "shell.execute_reply": "2025-12-11T03:54:37.463449Z",
     "shell.execute_reply.started": "2025-12-11T03:54:37.459452Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 1\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f21a53d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-04T06:40:26.997143Z",
     "iopub.status.busy": "2025-12-04T06:40:26.996809Z",
     "iopub.status.idle": "2025-12-04T06:40:27.005267Z",
     "shell.execute_reply": "2025-12-04T06:40:27.004282Z",
     "shell.execute_reply.started": "2025-12-04T06:40:26.997122Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "1 - 384\n",
    "\n",
    "\n",
    "40 - 256\n",
    "\n",
    "750 - 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa16562",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T03:54:37.466039Z",
     "iopub.status.busy": "2025-12-11T03:54:37.465595Z",
     "iopub.status.idle": "2025-12-11T03:54:42.540248Z",
     "shell.execute_reply": "2025-12-11T03:54:42.539171Z",
     "shell.execute_reply.started": "2025-12-11T03:54:37.466007Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import warnings\n",
    "from typing import Tuple, Optional, Dict, List, Callable\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "images_path = \"/kaggle/input/vesuvius-surface-npz/train_images\"\n",
    "mask_path = \"/kaggle/input/vesuvius-surface-npz/train_labels\"\n",
    "root_dir = \"/kaggle/input/vesuvius-surface-npz\"\n",
    "test_images_path = \"/kaggle/input/vesuvius-challenge-surface-detection/test_images\"\n",
    "OUTPUT_DIR = \"/kaggle/working/checkpoints\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7291dfd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T04:16:32.166397Z",
     "iopub.status.busy": "2025-12-11T04:16:32.166039Z",
     "iopub.status.idle": "2025-12-11T04:16:32.172397Z",
     "shell.execute_reply": "2025-12-11T04:16:32.171332Z",
     "shell.execute_reply.started": "2025-12-11T04:16:32.166373Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for a,b,c in os.walk(OUTPUT_DIR):\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f32275d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T03:54:42.541714Z",
     "iopub.status.busy": "2025-12-11T03:54:42.541203Z",
     "iopub.status.idle": "2025-12-11T03:54:42.547544Z",
     "shell.execute_reply": "2025-12-11T03:54:42.546463Z",
     "shell.execute_reply.started": "2025-12-11T03:54:42.541682Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.lr = 1e-4\n",
    "        self.num_workers = 2\n",
    "        self.batches = 1\n",
    "        self.val_split = 0.2\n",
    "        self.target_shape = (128,128,128)\n",
    "        self.weight_decay = 2e-4\n",
    "        self.max_epochs = 50\n",
    "        \n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a172ef2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T03:54:42.548961Z",
     "iopub.status.busy": "2025-12-11T03:54:42.548649Z",
     "iopub.status.idle": "2025-12-11T03:55:07.639490Z",
     "shell.execute_reply": "2025-12-11T03:55:07.638373Z",
     "shell.execute_reply.started": "2025-12-11T03:54:42.548931Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tifffile\n",
    "import pytorch_lightning as pl\n",
    "import random\n",
    "from monai import transforms as MT\n",
    "class VesuviusDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 images_id: list, \n",
    "                 images_dir: str = images_path, \n",
    "                 test_dir: str = test_images_path,   \n",
    "                 masks_dir: str = mask_path, \n",
    "                 mode: str = \"train\"):\n",
    "        \n",
    "        self.images_id = images_id\n",
    "        self.mode = mode\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.masks_dir = Path(masks_dir) if masks_dir else None\n",
    "        self.test_dir = Path(test_dir) if test_dir else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_id)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.images_id[idx]\n",
    "        \n",
    "        # 1. Determine Source Directory\n",
    "        if self.mode == \"test\":\n",
    "            if self.test_dir is None:\n",
    "                raise ValueError(\"Mode is 'test' but no 'test_dir' was provided!\")\n",
    "            source_dir = self.test_dir\n",
    "        else:\n",
    "            # Both 'train' and 'val' come from the training images directory\n",
    "            source_dir = self.images_dir\n",
    "\n",
    "        # 2. Load Image\n",
    "        img_path = source_dir / file_name\n",
    "        img = self.load_volume(img_path)\n",
    "\n",
    "        # 3. Load Mask (For both Train AND Val)\n",
    "        if self.mode in [\"train\", \"val\"]:\n",
    "            if self.masks_dir is None:\n",
    "                raise ValueError(f\"Mode is '{self.mode}' but no 'masks_dir' was provided!\")\n",
    "            \n",
    "            mask_path = self.masks_dir / file_name\n",
    "            mask = self.load_volume(mask_path, is_mask=True)\n",
    "            return img, mask, file_name\n",
    "            \n",
    "        # 4. Test mode (No mask)\n",
    "        else:\n",
    "            return img, None, file_name\n",
    "\n",
    "    def load_volume(self, file_path, is_mask=False):\n",
    "        path_obj = Path(file_path)\n",
    "        if not path_obj.exists():\n",
    "            raise FileNotFoundError(f\"Could not find file: {path_obj}\")\n",
    "        if path_obj.suffix == \".npz\":\n",
    "            archive = np.load(str(path_obj))\n",
    "            data = archive[list(archive.files)[0]]\n",
    "        elif path_obj.suffix in [\".tif\", \".tiff\"]:\n",
    "            data = tifffile.imread(str(path_obj))\n",
    "        else:\n",
    "            data = np.load(str(path_obj))\n",
    "        tensor = torch.from_numpy(data)\n",
    "\n",
    "        if not is_mask:\n",
    "            tensor = tensor.half().div_(255.0).unsqueeze(0)\n",
    "        else:\n",
    "            tensor = tensor.long().unsqueeze(0)\n",
    "\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8e1380",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T03:55:07.641173Z",
     "iopub.status.busy": "2025-12-11T03:55:07.640447Z",
     "iopub.status.idle": "2025-12-11T03:55:08.636332Z",
     "shell.execute_reply": "2025-12-11T03:55:08.635446Z",
     "shell.execute_reply.started": "2025-12-11T03:55:07.641145Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "images_id = None\n",
    "for _,_,c in os.walk(images_path):\n",
    "    images_id = c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6710dcaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T03:55:08.639201Z",
     "iopub.status.busy": "2025-12-11T03:55:08.638905Z",
     "iopub.status.idle": "2025-12-11T03:55:08.644049Z",
     "shell.execute_reply": "2025-12-11T03:55:08.642737Z",
     "shell.execute_reply.started": "2025-12-11T03:55:08.639177Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_collate(batch):\n",
    "    return batch\n",
    "#we want colation on happen on gpu as cpu cant do heavy interpolation\n",
    "#skipping the collation in dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4993e724",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T03:55:08.645348Z",
     "iopub.status.busy": "2025-12-11T03:55:08.645065Z",
     "iopub.status.idle": "2025-12-11T03:55:08.664628Z",
     "shell.execute_reply": "2025-12-11T03:55:08.663708Z",
     "shell.execute_reply.started": "2025-12-11T03:55:08.645323Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning \n",
    "class DesuviusDataModule(pl.LightningDataModule):\n",
    "\n",
    "    def __init__(self,\n",
    "                 train_img_dir = images_path,\n",
    "                 test_img_dir = test_images_path,\n",
    "                 mask_img_dir = mask_path,\n",
    "                 num_workers = config.num_workers,\n",
    "                 batches = config.batches,\n",
    "                 target_shape = config.target_shape):\n",
    "        super().__init__()\n",
    "        self.train_img_dir = train_img_dir\n",
    "        self.test_img_dir= test_img_dir\n",
    "        self.mask_img_dir = mask_img_dir\n",
    "        self.num_workers = num_workers\n",
    "        self.batches = batches\n",
    "        self.target_shape = target_shape\n",
    "        self.val_split = config.val_split\n",
    "\n",
    "        self.train_dataset = None\n",
    "        self.test_dataset = None\n",
    "        self.mask_dataset = None\n",
    "\n",
    "        self.gpu_augments = MT.Compose([\n",
    "            MT.Resized(keys=[\"image\", \"label\"], spatial_size=self.target_shape, mode=[\"trilinear\", \"nearest\"]),\n",
    "            MT.RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "            MT.RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
    "            MT.RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
    "            MT.RandRotated(keys=[\"image\", \"label\"], range_x=0.1, range_y=0.1, range_z=0.1, prob=0.3, keep_size=True, mode=[\"bilinear\", \"nearest\"]),\n",
    "            MT.RandShiftIntensityd(keys=[\"image\"], offsets=0.1, prob=0.5),\n",
    "            MT.RandGaussianNoised(keys=[\"image\"], prob=0.3, mean=0.0, std=0.01),\n",
    "        ])\n",
    "        # Validation transforms: Just Resize (for image AND label)\n",
    "        self.val_augments = MT.Compose([\n",
    "            MT.Resized(keys=[\"image\", \"label\"], spatial_size=self.target_shape, mode=[\"trilinear\", \"nearest\"])\n",
    "        ])\n",
    "        # Validation transforms for Image ONLY (for test set where labels are None)\n",
    "        self.val_image_augments = MT.Compose([\n",
    "            MT.Resized(keys=[\"image\"], spatial_size=self.target_shape, mode=[\"trilinear\"])\n",
    "        ])\n",
    "\n",
    "    def setup(self, stage = None):\n",
    "        random.seed(32)\n",
    "        all_files = images_id # Assumes images_id is defined globally\n",
    "        random.shuffle(all_files)\n",
    "        # Split into train/val\n",
    "        split_idx = int(len(all_files) * (1 - self.val_split))\n",
    "        train_files = all_files[:split_idx]\n",
    "        val_files = all_files[split_idx:]\n",
    "        print(f\"Total files: {len(all_files)}\")\n",
    "        print(f\"Train files: {len(train_files)}\")\n",
    "        print(f\"Val files: {len(val_files)}\")\n",
    "\n",
    "        # FIX: Use the split files, not the global list\n",
    "        self.train_dataset = VesuviusDataset(images_id = train_files, mode = \"train\")\n",
    "        self.val_dataset = VesuviusDataset(images_id = val_files, mode = \"val\")\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size = self.batches,\n",
    "            shuffle = True,\n",
    "            num_workers = self.num_workers,\n",
    "            pin_memory = True,\n",
    "            persistent_workers=bool(self.num_workers > 0),\n",
    "            collate_fn = custom_collate\n",
    "        )\n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size = self.batches,\n",
    "            shuffle = False, # FIX: Should be False for validation\n",
    "            num_workers = self.num_workers,\n",
    "            pin_memory = True,\n",
    "            persistent_workers=bool(self.num_workers > 0),\n",
    "            collate_fn = custom_collate\n",
    "        )\n",
    "\n",
    "    def on_after_batch_transfer(self, batch, dataloader_idx): \n",
    "        if not isinstance(batch, list):\n",
    "            return super().on_after_batch_transfer(batch, dataloader_idx)\n",
    "\n",
    "        x_list, y_list, frag_ids = [], [], [] # FIX: renamed z_list to frag_ids\n",
    "        \n",
    "        # Determine device\n",
    "        device = self.trainer.strategy.root_device if self.trainer else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        for item in batch:\n",
    "            x, y, frag_id = item\n",
    "            x = x.to(device, non_blocking=True)\n",
    "            \n",
    "            # Logic: If we are training, use gpu_augments. \n",
    "            # If validating and y exists, use val_augments.\n",
    "            # If y is None (predict), use val_image_augments.\n",
    "            \n",
    "            if y is not None:\n",
    "                y = y.to(device, non_blocking=True)\n",
    "                data = {\"image\": x, \"label\": y}\n",
    "                \n",
    "                # Pick transform\n",
    "                if self.trainer.training:\n",
    "                    trans = self.gpu_augments\n",
    "                else:\n",
    "                    trans = self.val_augments\n",
    "                \n",
    "                data = trans(data) # FIX: Use selected transform\n",
    "                y_list.append(data[\"label\"])\n",
    "            else:\n",
    "                # Prediction case (No Label)\n",
    "                data = {\"image\": x}\n",
    "                trans = self.val_image_augments\n",
    "                data = trans(data)\n",
    "                # Do not append to y_list\n",
    "            \n",
    "            x_list.append(data[\"image\"])\n",
    "            frag_ids.append(frag_id)\n",
    "\n",
    "        # Handle Y stack (if empty)\n",
    "        y_stack = torch.stack(y_list) if len(y_list) > 0 else None\n",
    "        \n",
    "        return torch.stack(x_list), y_stack, frag_ids # FIX: Return list frag_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9374390",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T03:55:08.666027Z",
     "iopub.status.busy": "2025-12-11T03:55:08.665702Z",
     "iopub.status.idle": "2025-12-11T03:55:08.697442Z",
     "shell.execute_reply": "2025-12-11T03:55:08.696430Z",
     "shell.execute_reply.started": "2025-12-11T03:55:08.666000Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataModule = DesuviusDataModule()\n",
    "dataModule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7453c29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T03:55:08.698772Z",
     "iopub.status.busy": "2025-12-11T03:55:08.698412Z",
     "iopub.status.idle": "2025-12-11T03:55:08.720053Z",
     "shell.execute_reply": "2025-12-11T03:55:08.718739Z",
     "shell.execute_reply.started": "2025-12-11T03:55:08.698728Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(dataModule.train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501b971e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T03:55:08.721431Z",
     "iopub.status.busy": "2025-12-11T03:55:08.721015Z",
     "iopub.status.idle": "2025-12-11T03:55:11.921123Z",
     "shell.execute_reply": "2025-12-11T03:55:11.919492Z",
     "shell.execute_reply.started": "2025-12-11T03:55:08.721399Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get a batch\n",
    "train_loader = dataModule.train_dataloader()\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "# With custom_collate, batch is a list: [(img, mask, id), ...]\n",
    "# We extract the first sample\n",
    "raw_img, raw_mask, frag_id = batch[0]\n",
    "\n",
    "print(f\"Raw ID: {frag_id}\")\n",
    "print(f\"Raw Image Shape: {raw_img.shape}\")\n",
    "\n",
    "# Manually apply the validation transform (Resize) to visualize the model input\n",
    "# We use val_augments which only contains Resized\n",
    "# Construct dictionary as expected by MONAI transforms\n",
    "data = {\"image\": raw_img, \"label\": raw_mask}\n",
    "data_resized = dataModule.val_augments(data)\n",
    "\n",
    "images = data_resized[\"image\"]\n",
    "masks = data_resized[\"label\"]\n",
    "\n",
    "# Select first channel\n",
    "img = images[0].numpy()  # (D, H, W)\n",
    "msk = masks[0].numpy()   # (D, H, W)\n",
    "\n",
    "print(f\"Resized Image Shape: {img.shape}\")\n",
    "print(f\"Mask Shape: {msk.shape}\")\n",
    "print(f\"Image Range: {img.min()} - {img.max()}\")\n",
    "\n",
    "# Calculate middle indices\n",
    "d_mid = img.shape[0] // 2\n",
    "h_mid = img.shape[1] // 2\n",
    "w_mid = img.shape[2] // 2\n",
    "\n",
    "# Setup plot: 3 Rows (Axes), 2 Cols (Image, Mask)\n",
    "fig, axes = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "# Row 1: Z-axis (Depth/Axial)\n",
    "axes[0, 0].imshow(img[d_mid, :, :], cmap='gray')\n",
    "axes[0, 0].set_title(f'Axial (Depth={d_mid}) - Image')\n",
    "axes[0, 1].imshow(msk[d_mid, :, :], cmap='gray')\n",
    "axes[0, 1].set_title(f'Axial (Depth={d_mid}) - Mask')\n",
    "\n",
    "# Row 2: Y-axis (Height/Coronal)\n",
    "axes[1, 0].imshow(img[:, h_mid, :], cmap='gray')\n",
    "axes[1, 0].set_title(f'Coronal (Height={h_mid}) - Image')\n",
    "axes[1, 1].imshow(msk[:, h_mid, :], cmap='gray')\n",
    "axes[1, 1].set_title(f'Coronal (Height={h_mid}) - Mask')\n",
    "\n",
    "# Row 3: X-axis (Width/Sagittal)\n",
    "axes[2, 0].imshow(img[:, :, w_mid], cmap='gray')\n",
    "axes[2, 0].set_title(f'Sagittal (Width={w_mid}) - Image')\n",
    "axes[2, 1].imshow(msk[:, :, w_mid], cmap='gray')\n",
    "axes[2, 1].set_title(f'Sagittal (Width={w_mid}) - Mask')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b44a9e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T03:55:11.923788Z",
     "iopub.status.busy": "2025-12-11T03:55:11.923318Z",
     "iopub.status.idle": "2025-12-11T03:55:11.955050Z",
     "shell.execute_reply": "2025-12-11T03:55:11.954064Z",
     "shell.execute_reply.started": "2025-12-11T03:55:11.923736Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "from monai.losses import TverskyLoss\n",
    "\n",
    "class surfaceSegementation(pl.LightningModule):\n",
    "    def __init__(self, net, learning_rate=1e-3, weight_decay=1e-4):\n",
    "        super().__init__()\n",
    "        # Fixed typo: save_hyperparameters\n",
    "        self.save_hyperparameters(ignore=[\"net\"])\n",
    "        # Fixed: assigned 'net' instead of undefined 'model'\n",
    "        self.net_module = net\n",
    "        # Fixed: removed undefined 'config' object and used init args\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.out_channels = 2\n",
    "        self.spatial_dims  = 3\n",
    "        self.ignore_index_val = 2\n",
    "        \n",
    "        self.crossEntropy = nn.CrossEntropyLoss(\n",
    "            ignore_index = self.ignore_index_val\n",
    "        )\n",
    "        self.Tversky = TverskyLoss(\n",
    "            softmax = True,\n",
    "            to_onehot_y = False,\n",
    "            include_background = True,\n",
    "            alpha = 0.75,\n",
    "            beta = 0.25  \n",
    "        )\n",
    "\n",
    "    # Added missing forward method required for self(img)\n",
    "    def forward(self, x):\n",
    "        return self.net_module(x)\n",
    "\n",
    "    def _compute_loss(self, logits, targets):\n",
    "        # pytorch cross entropy can ignore classes inherintly\n",
    "        targets = targets.squeeze(1)\n",
    "        ce_loss = self.crossEntropy(logits, targets.long())\n",
    "        \n",
    "        # mask so tversky doesnt get confused by class 2 as it cant ignore it natively\n",
    "        # Fixed: Changed 'target' to 'targets'\n",
    "        mask = (targets != self.ignore_index_val)\n",
    "        \n",
    "        # setting index 2 to 0\n",
    "        # Fixed: Changed 'target' to 'targets'\n",
    "        target_clean = torch.where(mask, targets, torch.tensor(0, device=targets.device))\n",
    "        \n",
    "        targets_onehot = torch.nn.functional.one_hot(\n",
    "            target_clean.long(),\n",
    "            num_classes=2\n",
    "        ).float()\n",
    "\n",
    "        # Fixed: Changed self.hparams.spatial_dims to self.spatial_dims\n",
    "        if self.spatial_dims == 3:\n",
    "            targets_onehot = targets_onehot.permute(0,4,1,2,3)\n",
    "        else:\n",
    "            targets_onehot = targets_onehot.permute(0,3,1,2) # Fixed permute for 2D\n",
    "        \n",
    "        # CHANGED: .half() -> .float() to prevent runtime errors on standard FP32 training\n",
    "        targets_masked_ohe = targets_onehot * mask.unsqueeze(1).float() \n",
    "\n",
    "        tversky_loss = self.Tversky(logits, targets_masked_ohe)\n",
    "\n",
    "        return 0.5*tversky_loss + 0.5*ce_loss\n",
    "\n",
    "    def _compute_metrics(self, preds_logits: torch.Tensor, targets_class_indices: torch.Tensor) -> dict:\n",
    "        \"\"\"\n",
    "        Computes Dice and IoU fully vectorized (No for-loops).\n",
    "        \"\"\"\n",
    "        num_classes = preds_logits.shape[1]\n",
    "        preds_hard = torch.argmax(preds_logits, dim=1, keepdim=True)\n",
    "        valid_mask = (targets_class_indices != self.ignore_index_val)\n",
    "        \n",
    "        # 3. One-Hot Encode Predictions\n",
    "        preds_ohe = torch.nn.functional.one_hot(\n",
    "            preds_hard.squeeze(1), \n",
    "            num_classes=num_classes\n",
    "        ).float()\n",
    "        \n",
    "        # 4. One-Hot Encode Targets\n",
    "        targets_clean = torch.where(valid_mask, targets_class_indices, torch.tensor(0, device=targets_class_indices.device))\n",
    "        \n",
    "        targets_ohe = torch.nn.functional.one_hot(\n",
    "            targets_clean.squeeze(1).long(), \n",
    "            num_classes=num_classes\n",
    "        ).float()\n",
    "\n",
    "        # Fixed: Changed self.hparams.spatial_dims to self.spatial_dims\n",
    "        if self.spatial_dims == 3:\n",
    "            preds_ohe = preds_ohe.permute(0, 4, 1, 2, 3)\n",
    "            targets_ohe = targets_ohe.permute(0, 4, 1, 2, 3)\n",
    "        else:\n",
    "            preds_ohe = preds_ohe.permute(0, 3, 1, 2)\n",
    "            targets_ohe = targets_ohe.permute(0, 3, 1, 2)\n",
    "\n",
    "        valid_mask_float = valid_mask.float()\n",
    "        preds_ohe = preds_ohe * valid_mask_float\n",
    "        targets_ohe = targets_ohe * valid_mask_float\n",
    "\n",
    "        # Fixed: Changed self.hparams.spatial_dims to self.spatial_dims\n",
    "        reduce_dims = (0, 2, 3, 4) if self.spatial_dims == 3 else (0, 2, 3)\n",
    "\n",
    "        intersection = (preds_ohe * targets_ohe).sum(dim=reduce_dims)\n",
    "        cardinality_pred = preds_ohe.sum(dim=reduce_dims)\n",
    "        cardinality_target = targets_ohe.sum(dim=reduce_dims)\n",
    "        \n",
    "        union_sum = cardinality_pred + cardinality_target\n",
    "\n",
    "        dice_scores = (2. * intersection + 1e-8) / (union_sum + 1e-8)\n",
    "        iou_scores = (intersection + 1e-8) / (union_sum - intersection + 1e-8)\n",
    "\n",
    "        return {\n",
    "            \"dice\": dice_scores.mean(),\n",
    "            \"iou\": iou_scores.mean()\n",
    "        }\n",
    "\n",
    "    # Added 'self' argument\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        img, mask, _ = batch\n",
    "        logits = self(img)\n",
    "        loss = self._compute_loss(logits, mask)\n",
    "        # Fixed function name _compute_metric -> _compute_metrics\n",
    "        # Fixed variable name metric -> metrics (to match logging below)\n",
    "        metrics = self._compute_metrics(logits, mask)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_dice\", metrics[\"dice\"], on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_iou\", metrics[\"iou\"], on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    # Added 'self' argument\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        img, mask, _ = batch\n",
    "        logits = self(img)\n",
    "        loss = self._compute_loss(logits, mask)\n",
    "        # Fixed function name _compute_metric -> _compute_metrics\n",
    "        # Fixed variable name metric -> metrics\n",
    "        metrics = self._compute_metrics(logits, mask)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_dice\", metrics[\"dice\"], on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_iou\", metrics[\"iou\"], on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    # Added 'self' argument and renamed to predict_step\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        img, _, frag_id = batch\n",
    "        logits = self(img)\n",
    "        prob = torch.softmax(logits, dim=1)\n",
    "        classes = torch.argmax(prob, dim=1)\n",
    "        return {\"prediction\": classes, \"frag_id\": frag_id}\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            # Fixed MAX_EPOCHS to use self.trainer.max_epochs\n",
    "            T_max=self.trainer.max_epochs if self.trainer else 100,\n",
    "            eta_min=1e-6\n",
    "        )\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"epoch\"\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55437d72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T03:55:11.956331Z",
     "iopub.status.busy": "2025-12-11T03:55:11.956029Z",
     "iopub.status.idle": "2025-12-11T03:55:12.770206Z",
     "shell.execute_reply": "2025-12-11T03:55:12.769149Z",
     "shell.execute_reply.started": "2025-12-11T03:55:11.956303Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from monai.networks.nets import SegResNet, SwinUNETR\n",
    "net = SwinUNETR(\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    feature_size=48,\n",
    "    use_v2=True,\n",
    "    drop_rate=0.2,\n",
    "    attn_drop_rate=0.2,\n",
    "    dropout_path_rate=0.2,\n",
    "    use_checkpoint=True\n",
    ")\n",
    "\n",
    "net_name = net.__class__.__name__\n",
    "model = surfaceSegementation(net=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd06f65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T03:58:39.823534Z",
     "iopub.status.busy": "2025-12-11T03:58:39.823177Z",
     "iopub.status.idle": "2025-12-11T03:58:39.828323Z",
     "shell.execute_reply": "2025-12-11T03:58:39.827321Z",
     "shell.execute_reply.started": "2025-12-11T03:58:39.823508Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"/kaggle/input/vesuvius-baseline-model/checkpoints/SwinUNETR-epoch=47-val_dice=0.7371.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d726e27d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T03:58:40.040794Z",
     "iopub.status.busy": "2025-12-11T03:58:40.040439Z",
     "iopub.status.idle": "2025-12-11T03:58:40.047458Z",
     "shell.execute_reply": "2025-12-11T03:58:40.046584Z",
     "shell.execute_reply.started": "2025-12-11T03:58:40.040770Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_files = []\n",
    "for inference_file,c,d in os.walk(\"/kaggle/input/vesuvius-challenge-surface-detection/test_images\"):\n",
    "    inference_files = d\n",
    "print(inference_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23039de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T03:58:42.074088Z",
     "iopub.status.busy": "2025-12-11T03:58:42.073755Z",
     "iopub.status.idle": "2025-12-11T03:58:48.207309Z",
     "shell.execute_reply": "2025-12-11T03:58:48.206243Z",
     "shell.execute_reply.started": "2025-12-11T03:58:42.074065Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model = surfaceSegementation.load_from_checkpoint(\n",
    "    checkpoint_path, \n",
    "    net=net\n",
    ")\n",
    "\n",
    "# 3. Prepare for Inference\n",
    "model.eval()        # Disables dropout/batchnorm updates\n",
    "model.freeze()      # Sets requires_grad=False to save memory\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fcc554",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T03:58:51.578085Z",
     "iopub.status.busy": "2025-12-11T03:58:51.577719Z",
     "iopub.status.idle": "2025-12-11T03:58:52.105295Z",
     "shell.execute_reply": "2025-12-11T03:58:52.104220Z",
     "shell.execute_reply.started": "2025-12-11T03:58:51.578062Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = VesuviusDataset(inference_files,mode = \"test\")\n",
    "img,_,_ = test_dataset.__getitem__(0)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a858a620",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T04:13:53.962154Z",
     "iopub.status.busy": "2025-12-11T04:13:53.961730Z",
     "iopub.status.idle": "2025-12-11T04:14:29.849519Z",
     "shell.execute_reply": "2025-12-11T04:14:29.848459Z",
     "shell.execute_reply.started": "2025-12-11T04:13:53.962130Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch.nn.functional as F\n",
    "import tifffile\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "predictions_tif = []\n",
    "\n",
    "\n",
    "for image, _, frag_id in tqdm(test_dataset, desc=\"Processing and saving 3D predictions\"):\n",
    "    image_on_device = image.to(model.device)\n",
    "    processed_data = dataModule.val_image_augments({\"image\": image_on_device})\n",
    "    \n",
    "    inputs_resized = processed_data[\"image\"].unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        frag_id_list = [frag_id]\n",
    "        \n",
    "        # Assuming predict_step handles the device transfer for inputs if needed\n",
    "        pred_dict = model.predict_step((inputs_resized, None, frag_id_list), 0)\n",
    "        \n",
    "        pred_class = pred_dict[\"prediction\"][0] # (D, H, W)\n",
    "\n",
    "        # Get original shape\n",
    "        # Verify this path points to a FILE, not a folder, unless it's a multi-file tif structure\n",
    "        image_path = Path(test_images_path) / Path(frag_id) \n",
    "        with tifffile.TiffFile(str(image_path)) as tif:\n",
    "            original_shape = tif.series[0].shape\n",
    "\n",
    "        # --- CRITICAL FIX ---\n",
    "        # Move to CPU before resizing to avoid VRAM OOM\n",
    "        pred_binary = pred_class.float().cpu()\n",
    "        \n",
    "        pred_input_tensor = pred_binary.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        pred_restored = F.interpolate(\n",
    "            pred_input_tensor,\n",
    "            size=original_shape,\n",
    "            mode='nearest'\n",
    "        ).squeeze(0).squeeze(0)\n",
    "\n",
    "    # Convert to uint8 (0, 1)\n",
    "    pred_saved = pred_restored.byte().numpy() # already on cpu\n",
    "    \n",
    "    # Save to TIFF\n",
    "    # prediction_tif_name = f\"{frag_id}.tif\"\n",
    "    prediction_tif_name = frag_id\n",
    "    save_path = Path(OUTPUT_DIR) / Path(prediction_tif_name)\n",
    "    tifffile.imwrite(str(save_path), pred_saved)\n",
    "    predictions_tif.append(prediction_tif_name)\n",
    "\n",
    "    # Optional: Clear cache to be safe if you are close to the limit\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Print the shape of the last processed fragment to verify\n",
    "print(f\"Last saved shape: {pred_saved.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb4bd84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T04:17:55.063446Z",
     "iopub.status.busy": "2025-12-11T04:17:55.062767Z",
     "iopub.status.idle": "2025-12-11T04:17:55.083085Z",
     "shell.execute_reply": "2025-12-11T04:17:55.082069Z",
     "shell.execute_reply.started": "2025-12-11T04:17:55.063418Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "print(f\"Zipping {len(predictions_tif)} files...\")\n",
    "with zipfile.ZipFile('submission.zip', 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for filename in tqdm(predictions_tif, desc=\"Zipping files\"):\n",
    "        if not os.path.exists(filename):\n",
    "            print(f\"Missing <> {filename}\")\n",
    "            continue\n",
    "        # Write to zip\n",
    "        zipf.write(filename)\n",
    "        # Remove original file to save space\n",
    "        os.remove(filename)\n",
    "\n",
    "print(\"Submission.zip created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f404f5a5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14443416,
     "sourceId": 117682,
     "sourceType": "competition"
    },
    {
     "datasetId": 8787846,
     "sourceId": 13802080,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8800020,
     "sourceId": 13818749,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8945494,
     "sourceId": 14063070,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8953734,
     "sourceId": 14066894,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 284794863,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-11T04:21:24.069359",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}